<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link href="css/style.css" rel="stylesheet">
    <link rel="icon" href="image/cropped-logo_MMSP-32x32.png">
    <title>Reproducible Neural Visual Coding</title>
</head>

<body>

    <!-- 导航栏 -->
    <div class="site-wrap">
        <div class="site-navbar">
            <nav class="site-navigation">
                <a href="https://attend.ieee.org/mmsp-2024/" width="50px">
                    <h1>RNVC</h1>
                </a>
                <ul class="site-menu">

                    <li>
                        <a href="index.html">HOME</a>
                    </li>
                    <li>
                        <a href="index.html#special session abstract">SPECIAL SESSION ABSTRACT</a>
                    </li>
                    <li>
                        <a href="index.html#important dates">IMPORTANT DATES</a>
                    </li>
                    <li>
                        <a href="index.html#paper submission">PAPER SUBMISSION</a>
                    </li>
                    <li>
                        <a href="index.html#organizing Co-chairs">ORGANIZING CO-CHAIRS</a>
                    </li>
                </ul>
            </nav>
        </div>
        <div class="workshop">
            <!-- <img src="image/workshop.jpg" id="workShopImage" </img> -->
            
        </div>
    </div>



    <div class="main">
        <!-- top -->
        <div class="left">
            <span class="section-title" id="organizing Co-chairs" style="font-size: 24px;"><strong>Special Session Chairs:</strong></span>
            <div class="session-chairs">
                
                <ul class="chairs-container">
                    <li class="chair-item">
            
                        <div class="chair-info">
                            <img src="image/Ma.jpg" alt="Zhan Ma" class="chair-photo">
                            <span class="chair-name"><strong>Zhan Ma</strong>, Nanjing University</span><br>
                            <span class="chair-email">mazhan@nju.edu.cn</span>
                            
                         </div>
                    </li>
                    <li class="chair-item">
            
                        <div class="chair-info">
                            <img src="image/Dong.jfif" alt="Dong Tian" class="chair-photo">
                            <span class="chair-name"><strong>Dong Tian</strong>, InterDigital</span><br>
                            <span class="chair-email">Dong.tian@interdigital.com</span>
                            
                        </div>
                    </li>
                    <!-- More chairs if needed -->
                </ul>
            </div>
            <div class="session-abstract">
                <span class="section-title" id="special session abstract" style="font-size: 24px;"><strong>Special Session Abstract:</strong></span>
                <p class="abstract-text">
                    In recent years, we have witnessed the exponential growth of research and development explorations on learning-based visual coding. These learned coding approaches, regardless of their focus on image, video, or 3D point cloud, have demonstrated remarkable improvement in coding efficiency compared to traditional solutions developed for decades.
                </p>
                <p class="abstract-text">
                    Although international standard organizations such as JPEG, MPEG, etc., have devoted efforts to promote learning-based visual coding techniques, they are often criticized for the lack of <strong>reproducibility</strong>. Reproducibility concerns the <strong>complexity</strong> and <strong>generalization</strong> of the underlying coding model, which is vital for faithfully evaluating the performance of these methods and ensuring the adoption in practical applications.  The complexity herein includes computational complexity and memory (space) consumption in both training and inference. The generalization ensures the applicability of the trained model in various data domains, even for unseen data.
                </p>
                <p class="abstract-text">
                    This special session seeks original contributions reporting and discussing the reproducibility of recently emerged neural visual coding solutions. It targets a mixed audience of researchers and product developers from several communities, i.e., multimedia coding, machine learning, computer vision, etc. The topics of interest include, but are not limited to:
                </p>
                <ul>
                    <li class="date"><span>Efficient Neural visual coding for image, video, 3D point cloud, etc.</span></li>
                    <li class="date"><span>Model complexity analysis of neural visual coding; </span></li>
                    <li class="date"><span>Model generalization studies of neural visual coding;</span></li>
                    <li class="date"><span>Standardization activity overview and relevant techniques summarization</span></li>
                    <li class="date"><span>Technical alignment of training and testing, e.g., dataset, procedural steps, etc., for fair comparison</span></li>
                </ul>
            </div>
            <div class="Important-Dates">
                <span class="title" id="important dates" style="font-size: 24px;"><strong>Important dates:</strong></span>
                <ul>
                    <li class="date"><span>Call for papers: <strong style="color:red;">submit by June 19, 2024</strong></span></li>
                </ul>
            </div>
            
            <div class="paper-Submission">
                <span class="title" id="paper submission" style="font-size: 24px;"><strong>Paper Submission:</strong></span>
                <p>
                    For detailed instructions, see <a href="https://attend.ieee.org/mmsp-2024/">https://attend.ieee.org/mmsp-2024/</a>.
                </p>
            </div>
        </div>
        <!--
        <div class="right">
            
            <div class="session-chairs">
                <span class="section-title" id="organizing Co-chairs"><strong>Special Session Chairs:</strong></span>
                <ul class="chairs-container">
                    <li class="chair-item">
            
                        <div class="chair-info">
                            <img src="image/Ma.jpg" alt="Zhan Ma" class="chair-photo" style="float: left;">
                            <span class="chair-name"><strong>Zhan Ma</strong>, Nanjing University</span><br>
                            <span class="chair-email">mazhan@nju.edu.cn</span>
                            <p class="chair-bio">
                                Short Bio: Zhan Ma has been a Professor at the Electronic Science and Engineering School of Nanjing University, China, since 2015. He received his Ph.D. from New York University, New York in 2011. From 2011 to 2014, he has been with Samsung Research America, Dallas TX, and Futurewei Technologies, Inc., Santa Clara, CA, respectively. His current research focuses on brain-inspired visual communication and computational. He is a co-recipient of the 2019 IEEE Broadcast Technology Society Best Paper Award, the 2020 IEEE MMSP Learned Image Coding Challenge Best Performing Solution, the 2023 IEEE WACV Best Paper Award (Algorithms), and the 2023 IEEE Circuits and Systems Society Outstanding Young Scholar. He served as the TPC member for IEEE ICME, MMSP, etc.
                            </p>
                         </div>
                    </li>
                    <li class="chair-item">
            
                        <div class="chair-info">
                            <img src="image/Dong.jfif" alt="Dong Tian" class="chair-photo" style="float: left;">
                            <span class="chair-name"><strong>Dong Tian</strong>, InterDigital</span><br>
                            <span class="chair-email">Dong.tian@interdigital.com</span>
                            <p class="chair-bio">
                                Short Bio: Dong Tian is currently a Senior Director with InterDigital in New York, NY. His research interests include image processing, 3D video, point cloud processing, graph signal processing, and deep learning. He has been actively contributing to both industry standards and academic communities for 20+ years on immersive video. Prior to InterDigital, Dr. Tian was a Senior Principal Research Scientist at MERL, Cambridge, MA from 2010-2018, a Senior Researcher with Thomson Corporate Research, Princeton, NJ from 2006-2010, and a Researcher at Tampere University of Technology (TUT) from 2002-2005. He holds 30+ US-granted patents and 50+ recent publications in top-tier journals/transactions and conferences. Dr. Tian serves as an AhG chair of MPEG 3DGH on AI-based Graphic Coding (2021-), a Chair of MSA TC (2023-2025), an Associate Editor of TIP (2018-2021,2021-2024), General Co-Chair of MMSP'20 and MMSP’21, TPC chair of MMSP'19, etc. He is a current TC advisory member of IEEE MMSP. Dong Tian received the B.S. and M.Sc degrees from the University of Science and Technology of China (USTC), Hefei, China, in 1995 and 1998, and the Ph.D. degree from Beijing University of Technology, Beijing, in 2001. He is a senior member of IEEE.
                            </p>
                        </div>
                    </li>
                    <!-- More chairs if needed -->
                </ul>
            </div>
            
                 
            
        </div>
        -->
    </div>
</body>

</html>
